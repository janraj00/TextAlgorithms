{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from typing import Callable\n",
    "from sklearn.cluster import DBSCAN\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from timeit import default_timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ngrams(text):\n",
    "    n_grams = defaultdict(lambda: 0)\n",
    "    for i in range(len(text) - N + 2):\n",
    "        n_grams[text[i:i + N]] += 1\n",
    "    return n_grams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metryka Levenshteina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Levenstein(a, b):\n",
    "    size_a: int = len(a)\n",
    "    size_b: int = len(b)\n",
    "    maximum = max(size_b, size_a)\n",
    "    L = [[0 for _ in range(size_b + 1)] for _ in range(size_a + 1)]\n",
    "    for i in range(size_b + 1):\n",
    "        L[0][i] = i\n",
    "\n",
    "    for i in range(size_a + 1):\n",
    "        L[i][0] = i\n",
    "\n",
    "    for i in range(1, size_a + 1):\n",
    "        for j in range(1, size_b + 1):\n",
    "            cost: int = 0\n",
    "            if a[i - 1] != b[j - 1]:\n",
    "                cost = 1\n",
    "            L[i][j] = min(L[i - 1][j] + 1, L[i][j - 1] + 1, L[i - 1][j - 1] + cost)\n",
    "    return L[-1][-1]/maximum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metryka Dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DICE_distance(line1, line2):\n",
    "    ngrams1 = make_ngrams(line1)\n",
    "    ngrams2 = make_ngrams(line2)\n",
    "    intersection = set(ngrams1.keys()) & set(ngrams2.keys())\n",
    "    return 1 - 2 * len(intersection) / (len(ngrams1.keys()) + len(ngrams2.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metryka euklidesowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(line1, line2):\n",
    "    ngrams1 = list(make_ngrams(line1).values())\n",
    "    ngrams2 = list(make_ngrams(line2).values())\n",
    "    if len(ngrams1) > len(ngrams2):\n",
    "        for i in range(len(ngrams1) - len(ngrams2)):\n",
    "            ngrams2.append(0)\n",
    "    else:\n",
    "        for i in range(len(ngrams2) - len(ngrams1)):\n",
    "            ngrams1.append(0)\n",
    "    n1 = np.array(ngrams1)\n",
    "    n2 = np.array(ngrams2)\n",
    "    dist = np.linalg.norm(n1 - n2)\n",
    "    return 1 / (1 + dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metryka LCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LCS_distance(line1, line2):\n",
    "    len_a = len(line1)\n",
    "    len_b = len(line2)\n",
    "    maximum: float = 0.0\n",
    "    C = [[0] * (len_b + 1) for _ in range(len_a + 1)]\n",
    "    for i in range(1, len_a + 1):\n",
    "        for j in range(1, len_b + 1):\n",
    "            if line1[i - 1] == line2[j - 1]:\n",
    "                C[i][j] = C[i - 1][j - 1] + 1\n",
    "                maximum = max(maximum, C[i][j])\n",
    "    return 1.0 - maximum / max(len_a, len_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stoplista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stoplist(lines, words_to_remove):\n",
    "    signs_to_remove = '\\'\"/:.;,()'\n",
    "    lines_dpcp = deepcopy(lines)\n",
    "    for i in range(len(lines_dpcp)):\n",
    "        for sign in signs_to_remove:\n",
    "            lines_dpcp[i] = lines_dpcp[i].replace(sign, ' ')\n",
    "    words_count = Counter()\n",
    "    split_lines = []\n",
    "    for line in lines_dpcp:\n",
    "        split_lines.append(line.split(' '))\n",
    "    for line in split_lines:\n",
    "        for word in line:\n",
    "            if word != '':\n",
    "                words_count[word] += 1\n",
    "    for i in range(len(lines_dpcp)):\n",
    "        for word in words_count:\n",
    "            lines_dpcp[i] = lines_dpcp[i].replace(word[0], ' ')\n",
    "    return lines_dpcp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macierz odległości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dist_matrix(lines, metric_function: Callable):\n",
    "    n = len(lines)\n",
    "    matrix = np.zeros((n, n))\n",
    "    for i in range(len(lines)):\n",
    "        line1 = lines[i]\n",
    "        for j in range(i, len(lines)):\n",
    "            line2 = lines[j]\n",
    "            p = metric_function(line1, line2)\n",
    "            matrix[i][j] = p\n",
    "            matrix[j][i] = p\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasteryzacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(lines, metric_fun: Callable, epsilon):\n",
    "    X: np.array = create_dist_matrix(lines, metric_fun)\n",
    "    clusters = DBSCAN(eps=epsilon, min_samples=2, metric=\"precomputed\").fit(X)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centroid(cluster, dist_matrix):\n",
    "    min_index = 0\n",
    "    min_val = 10**5\n",
    "    mean = 0\n",
    "    for elem in cluster:\n",
    "        elem_sum = 0\n",
    "        for neighbour in cluster:\n",
    "            if neighbour != elem:\n",
    "                elem_sum += dist_matrix[elem][neighbour]\n",
    "        mean += elem_sum\n",
    "        if elem_sum < min_val:\n",
    "            min_val = elem_sum\n",
    "            min_index = elem\n",
    "    mean = mean/(2*len(cluster))\n",
    "    return min_index, mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dunn index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dunn_index(clusters_set: DBSCAN, dist_matrix):\n",
    "    labels = clusters_set.labels_\n",
    "    n = max(labels) + 1\n",
    "    T = [[] for _ in range(n)]\n",
    "    min_d = 10 ** 5\n",
    "    max_size = 0\n",
    "    centroids = []\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] != -1:\n",
    "            T[labels[i]].append(i)\n",
    "    for elem in T:\n",
    "        centroids.append(find_centroid(elem, dist_matrix)[0])\n",
    "    for i in range(n):\n",
    "        max_size = max(max_size, len(T[i]))\n",
    "        for j in range(i+1, n):\n",
    "            p = dist_matrix[centroids[i]][centroids[j]]\n",
    "            min_d = min(p, min_d)\n",
    "    return min_d / max_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Davies-Bouldin index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DB_index(clusters_set: DBSCAN, dist_matrix):\n",
    "    labels = clusters_set.labels_\n",
    "    n = max(labels) + 1\n",
    "    T = [[] for _ in range(n)]\n",
    "    centroids = [0 for _ in range(n)]\n",
    "    means = [0 for _ in range(n)]\n",
    "    max_val = 0\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] != -1:\n",
    "            T[labels[i]].append(i)\n",
    "    for i in range(n):\n",
    "        elems = T[i]\n",
    "        c, m = find_centroid(elems, dist_matrix)\n",
    "        means[i] = m\n",
    "        centroids[i] = c\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                val = (means[i] + means[j])/dist_matrix[i][j]\n",
    "                max_val = max(max_val, val)\n",
    "    return max_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(lines_set, algorithm: Callable, lines_num, slist_size, epsilon):\n",
    "    data = lines_set[:lines_num]\n",
    "    if slist_size > 0:\n",
    "        data = create_stoplist(data, slist_size)\n",
    "    start = default_timer()\n",
    "    clusters, dist_matrix = clustering(data, algorithm, epsilon)\n",
    "    end = default_timer()\n",
    "    d_ind = Dunn_index(clusters, dist_matrix)\n",
    "    db_ind = DB_index(clusters, dist_matrix)\n",
    "    print(\"Ilość linii:\", lines_num)\n",
    "    print(\"Czas realizacji:\", end-start)\n",
    "    print(\"Indeks Dunna:\", d_ind)\n",
    "    print(\"Indeks Daviesa-Bouldina\", db_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lines.txt\", \"r\") as file:\n",
    "    lines = file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metryka euklidesowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z użyciem stoplisty\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable DBSCAN object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-594128b5b13c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Z użyciem stoplisty\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrun_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meuclidean_distance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Bez użycia stoplisty\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrun_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meuclidean_distance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-44d2f3da989b>\u001b[0m in \u001b[0;36mrun_test\u001b[1;34m(lines_set, algorithm, lines_num, slist_size, epsilon)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_stoplist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslist_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefault_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mclusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclustering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefault_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0md_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDunn_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable DBSCAN object"
     ]
    }
   ],
   "source": [
    "print(\"Z użyciem stoplisty\")\n",
    "run_test(lines, euclidean_distance, 100, 10, 0.3)\n",
    "print(\"Bez użycia stoplisty\")\n",
    "run_test(lines, euclidean_distance, 100, 10, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
